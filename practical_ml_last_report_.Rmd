---
title: "Week4 peer review assignment."
author: "Lee"
date: "April 17, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Synopsis
This assignment is about predicting the phisical activity by some data. classe feature of training data is the target that we're going to predict.    
This dataset has more than 100 features and some of them is meaningless such as X and user name and so on. I extracted numeric data  because umeric data is more meaningful than others.   
At first, I tried randomforest of caret. But it didnt's work. I found some solution about it in discussion board. But it still took so long. I decided to use randomForest package in direct.   
10 fold cross validation is implemented from the scratch. There must be a better way.But I wanted to experience it by myself.
The accuracy is so high. it's more than 99%.  

# Loading data & basic information
This dataset is not big. 
seed is not needed at the moment.it's added just for the future
```{r}
#library(caret)
library(randomForest)
training <- read.csv("pml-training.csv")
testing <- read.csv("pml-testing.csv")

dim(training)
#head(training)

dim(testing)

set.seed(20170417)
```


# feature extraction
I only use numeric features. It was enough in order to get a high accuracy.   
numeric_only[1] is just an index. It doesn't say anything and have to be erased.
classe feature must be added because it's a target.
```{r}
numeric_only <- sapply(testing, is.numeric)
numeric_only[1] <- FALSE

essential <- training[,numeric_only]

essential$classe <- training$classe

```




# training using whole training dataset 
random forest of caret package doesn't seem to work well.   
randomForest is used directly.  
perfect score(20/20) in prediction quiz was gained.

```{r}
##it doesn't work...
##fit <- train(classe ~ . , data= essential ,method="rf")

model <- randomForest(classe ~. , data = essential)
out <- predict(model, newdata=testing[,numeric_only])
print(out)

```







# 10 fold cross validation.
essential is the feature extracted dataset from upper.  
"kfold" feature is added to identify which fold it is.
1:10 is repeated  (nrows - nrows%%10)/10 times. nrows - nrows%%10 calculate the rest. next for loop is for appending kfold value to the rest rows.  
If kfold is 1 ,it means it's 1 fold. If kfold is 2, it means it's 2 fold and so on.
grep function is for removing kfold becuase kfold is just added for cross valication.   
each accuracy is saved in result vector.at last, overall 10 fold cross validation accuracy is showed.


```{r}


nrows <- nrow(essential)
fold_num <- rep(1:10 , times=(nrows - nrows%%10 )/10 )

for(i in range(1: (nrows%%10)))
{
  fold_num <- c(fold_num,i)
}

essential[,"kfold"] <- fold_num

result <- c()
for(i in 1:10)
{
  train_data <- essential[ essential[,"kfold"] != i , -grep("kfold", colnames(essential))]
  testing_data <-essential[ essential[,"kfold"] == i , -grep("kfold", colnames(essential))]

  ffit <- randomForest(classe ~ . , data = train_data )
  out <- predict(ffit, newdata=testing_data)
  
  #accuracy
  correct_cnt = sum( essential[ essential[,"kfold"] == i ,]$classe == out)
  result <- c(result, (correct_cnt /(nrows/10))*100 )
}

#10 fold cross validation accuracy!
print( sum(result)/10)
```

